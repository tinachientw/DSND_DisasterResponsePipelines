{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90caedbc",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "* Import Python libraries\n",
    "* Load dataset from database with read_sql_table\n",
    "* Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467ec455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (4.14.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/env_udacity_ds/lib/python3.6/site-packages (from plotly) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tina 1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/tina\n",
      "[nltk_data]     1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tina 1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tina 1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install plotly\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(['punkt','stopwords','wordnet'])\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score,label_ranking_average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2842a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(db_path='../data/disaster.db',tablename='_table'):\n",
    "    \"\"\"\n",
    "    Function: load data from database and return X and y.\n",
    "    Args:\n",
    "      db_path(str): database file name included path\n",
    "      tablename:(str): table name in the database file.\n",
    "    Return:\n",
    "      X(pd.DataFrame): messages for X\n",
    "      y(pd.DataFrame): labels part in messages for y\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data from database\n",
    "    engine = create_engine('sqlite:///'+db_path)\n",
    "    table_name = os.path.basename(db_path).replace(\".db\",\"\") + \"_table\"\n",
    "    df = pd.read_sql_table(table_name,engine)\n",
    "    \n",
    "    #Remove child alone as it has all zeros only\n",
    "    df = df.drop(['child_alone'],axis=1)\n",
    "    df['related']=df['related'].map(lambda x: 1 if x == 2 else x)\n",
    "    X = df['message']\n",
    "    y = df.iloc[:,4:]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd61891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_data()\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4aedaa",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdfee73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text,url_place_holder_string=\"urlplaceholder\"):\n",
    "    \"\"\"\n",
    "    Tokenize the text function\n",
    "    \n",
    "    Arguments:\n",
    "        text -> Text message which needs to be tokenized\n",
    "    Output:\n",
    "        clean_tokens -> List of tokens extracted from the provided text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace all urls with a urlplaceholder string\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    # Extract all the urls from the provided text \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # Replace url with a url placeholder string\n",
    "    for detected_url in detected_urls:\n",
    "        text = text.replace(detected_url, url_place_holder_string)\n",
    "\n",
    "    # Extract the word tokens from the provided text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #Lemmanitizer to remove inflectional and derivationally related forms of a word\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    # List of clean tokens\n",
    "    clean_tokens = [lemmatizer.lemmatize(w).lower().strip() for w in tokens]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3761f",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb22a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf_transformer', TfidfTransformer())\n",
    "        ]))\n",
    "            \n",
    "    ])),\n",
    "\n",
    "    ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66c452",
   "metadata": {},
   "source": [
    "### 4. Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7555aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                 Pipeline(steps=[('count_vectorizer',\n",
       "                                                                  CountVectorizer(tokenizer=<function tokenize at 0x7f9b855b8bf8>)),\n",
       "                                                                 ('tfidf_transformer',\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                ('classifier',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier()))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d61a3",
   "metadata": {},
   "source": [
    "### 5. Test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0581e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, y_pred):\n",
    "    result=precision_recall_fscore_support(y_test, y_pred)\n",
    "    for i, col in enumerate(y_test.columns.values): #category_names\n",
    "        accu=accuracy_score(y_test.loc[:,col],y_pred[:,i])\n",
    "        print('{}\\n Accuracy: {:.4f}    % Precision: {:.4f}   % Recall {:.4f} '.format(\n",
    "            col,accu,result[0][i],result[1][i]))\n",
    "    avg_precision = label_ranking_average_precision_score(y_test, y_pred)\n",
    "    avg_score= ('label ranking average precision: {}'.format(avg_precision))\n",
    "    print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d4ea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation model\n",
      "related\n",
      " Accuracy: 0.8077    % Precision: 0.8313   % Recall 0.9403 \n",
      "request\n",
      " Accuracy: 0.8987    % Precision: 0.7938   % Recall 0.5501 \n",
      "offer\n",
      " Accuracy: 0.9953    % Precision: 0.4000   % Recall 0.0851 \n",
      "aid_related\n",
      " Accuracy: 0.7620    % Precision: 0.7736   % Recall 0.6022 \n",
      "medical_help\n",
      " Accuracy: 0.9323    % Precision: 0.6624   % Recall 0.2844 \n",
      "medical_products\n",
      " Accuracy: 0.9619    % Precision: 0.7233   % Recall 0.3665 \n",
      "search_and_rescue\n",
      " Accuracy: 0.9756    % Precision: 0.6995   % Recall 0.2296 \n",
      "security\n",
      " Accuracy: 0.9817    % Precision: 0.4384   % Recall 0.0853 \n",
      "military\n",
      " Accuracy: 0.9734    % Precision: 0.6809   % Recall 0.3860 \n",
      "water\n",
      " Accuracy: 0.9674    % Precision: 0.7819   % Recall 0.6784 \n",
      "food\n",
      " Accuracy: 0.9476    % Precision: 0.8199   % Recall 0.6794 \n",
      "shelter\n",
      " Accuracy: 0.9486    % Precision: 0.7975   % Recall 0.5569 \n",
      "clothing\n",
      " Accuracy: 0.9892    % Precision: 0.7583   % Recall 0.4776 \n",
      "money\n",
      " Accuracy: 0.9806    % Precision: 0.6616   % Recall 0.3537 \n",
      "missing_people\n",
      " Accuracy: 0.9900    % Precision: 0.6866   % Recall 0.1957 \n",
      "refugees\n",
      " Accuracy: 0.9701    % Precision: 0.6403   % Recall 0.2525 \n",
      "death\n",
      " Accuracy: 0.9710    % Precision: 0.7674   % Recall 0.5121 \n",
      "other_aid\n",
      " Accuracy: 0.8757    % Precision: 0.5866   % Recall 0.1808 \n",
      "infrastructure_related\n",
      " Accuracy: 0.9360    % Precision: 0.5471   % Recall 0.1103 \n",
      "transport\n",
      " Accuracy: 0.9614    % Precision: 0.7401   % Recall 0.2505 \n",
      "buildings\n",
      " Accuracy: 0.9618    % Precision: 0.6938   % Recall 0.4408 \n",
      "electricity\n",
      " Accuracy: 0.9829    % Precision: 0.6453   % Recall 0.3141 \n",
      "tools\n",
      " Accuracy: 0.9940    % Precision: 0.4615   % Recall 0.0968 \n",
      "hospitals\n",
      " Accuracy: 0.9887    % Precision: 0.4571   % Recall 0.1385 \n",
      "shops\n",
      " Accuracy: 0.9957    % Precision: 0.6667   % Recall 0.0842 \n",
      "aid_centers\n",
      " Accuracy: 0.9879    % Precision: 0.4444   % Recall 0.1469 \n",
      "other_infrastructure\n",
      " Accuracy: 0.9549    % Precision: 0.4576   % Recall 0.1166 \n",
      "weather_related\n",
      " Accuracy: 0.8771    % Precision: 0.8643   % Recall 0.6613 \n",
      "floods\n",
      " Accuracy: 0.9568    % Precision: 0.8787   % Recall 0.5505 \n",
      "storm\n",
      " Accuracy: 0.9440    % Precision: 0.7907   % Recall 0.5463 \n",
      "fire\n",
      " Accuracy: 0.9908    % Precision: 0.7045   % Recall 0.2707 \n",
      "earthquake\n",
      " Accuracy: 0.9715    % Precision: 0.8938   % Recall 0.7856 \n",
      "cold\n",
      " Accuracy: 0.9842    % Precision: 0.7387   % Recall 0.3451 \n",
      "other_weather\n",
      " Accuracy: 0.9498    % Precision: 0.5745   % Recall 0.1948 \n",
      "direct_report\n",
      " Accuracy: 0.8713    % Precision: 0.7553   % Recall 0.4967 \n",
      "label ranking average precision: 0.7219547822579523\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation model\")\n",
    "\n",
    "y_prediction_train = pipeline.predict(X_train)\n",
    "y_prediction_test = pipeline.predict(X_test)\n",
    "\n",
    "evaluate_model(y_train, y_prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b30ce21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      " Accuracy: 0.8018    % Precision: 0.8280   % Recall 0.9342 \n",
      "request\n",
      " Accuracy: 0.8972    % Precision: 0.7953   % Recall 0.5320 \n",
      "offer\n",
      " Accuracy: 0.9949    % Precision: 0.0000   % Recall 0.0000 \n",
      "aid_related\n",
      " Accuracy: 0.7549    % Precision: 0.7682   % Recall 0.5818 \n",
      "medical_help\n",
      " Accuracy: 0.9252    % Precision: 0.6138   % Recall 0.2667 \n",
      "medical_products\n",
      " Accuracy: 0.9525    % Precision: 0.6027   % Recall 0.3154 \n",
      "search_and_rescue\n",
      " Accuracy: 0.9760    % Precision: 0.6316   % Recall 0.1765 \n",
      "security\n",
      " Accuracy: 0.9796    % Precision: 0.1333   % Recall 0.0208 \n",
      "military\n",
      " Accuracy: 0.9720    % Precision: 0.5775   % Recall 0.2595 \n",
      "water\n",
      " Accuracy: 0.9599    % Precision: 0.7148   % Recall 0.6209 \n",
      "food\n",
      " Accuracy: 0.9521    % Precision: 0.8491   % Recall 0.6935 \n",
      "shelter\n",
      " Accuracy: 0.9460    % Precision: 0.7697   % Recall 0.5641 \n",
      "clothing\n",
      " Accuracy: 0.9907    % Precision: 0.7838   % Recall 0.4143 \n",
      "money\n",
      " Accuracy: 0.9798    % Precision: 0.5556   % Recall 0.2679 \n",
      "missing_people\n",
      " Accuracy: 0.9878    % Precision: 0.4737   % Recall 0.1429 \n",
      "refugees\n",
      " Accuracy: 0.9697    % Precision: 0.5714   % Recall 0.2588 \n",
      "death\n",
      " Accuracy: 0.9691    % Precision: 0.7815   % Recall 0.4777 \n",
      "other_aid\n",
      " Accuracy: 0.8640    % Precision: 0.4525   % Recall 0.1445 \n",
      "infrastructure_related\n",
      " Accuracy: 0.9352    % Precision: 0.4706   % Recall 0.0952 \n",
      "transport\n",
      " Accuracy: 0.9592    % Precision: 0.6667   % Recall 0.1787 \n",
      "buildings\n",
      " Accuracy: 0.9594    % Precision: 0.7029   % Recall 0.3606 \n",
      "electricity\n",
      " Accuracy: 0.9796    % Precision: 0.6000   % Recall 0.2087 \n",
      "tools\n",
      " Accuracy: 0.9928    % Precision: 0.2857   % Recall 0.0571 \n",
      "hospitals\n",
      " Accuracy: 0.9893    % Precision: 0.3750   % Recall 0.1154 \n",
      "shops\n",
      " Accuracy: 0.9947    % Precision: 0.2000   % Recall 0.0400 \n",
      "aid_centers\n",
      " Accuracy: 0.9855    % Precision: 0.2273   % Recall 0.0781 \n",
      "other_infrastructure\n",
      " Accuracy: 0.9535    % Precision: 0.3137   % Recall 0.0711 \n",
      "weather_related\n",
      " Accuracy: 0.8716    % Precision: 0.8609   % Recall 0.6474 \n",
      "floods\n",
      " Accuracy: 0.9575    % Precision: 0.9160   % Recall 0.5313 \n",
      "storm\n",
      " Accuracy: 0.9405    % Precision: 0.7668   % Recall 0.5010 \n",
      "fire\n",
      " Accuracy: 0.9895    % Precision: 0.4500   % Recall 0.1698 \n",
      "earthquake\n",
      " Accuracy: 0.9693    % Precision: 0.8899   % Recall 0.7845 \n",
      "cold\n",
      " Accuracy: 0.9840    % Precision: 0.7083   % Recall 0.3269 \n",
      "other_weather\n",
      " Accuracy: 0.9479    % Precision: 0.4694   % Recall 0.1723 \n",
      "direct_report\n",
      " Accuracy: 0.8592    % Precision: 0.7073   % Recall 0.4594 \n",
      "label ranking average precision: 0.7079240779396507\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, y_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807f282",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf13673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=10, score=0.466, total=  22.8s\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=10, score=0.455, total=  22.8s\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   45.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=10, score=0.464, total=  22.9s\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=20, score=0.452, total=  37.6s\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=20, score=0.453, total=  39.9s\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=20, score=0.450, total=  38.7s\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=40, score=0.425, total= 1.1min\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=40, score=0.437, total= 1.1min\n",
      "[CV] classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.01, classifier__estimator__n_estimators=40, score=0.430, total= 1.2min\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=10, score=0.454, total=  22.9s\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=10, score=0.453, total=  23.0s\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=10, score=0.447, total=  22.6s\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=20, score=0.425, total=  38.3s\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=20, score=0.436, total=  38.8s\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=20, score=0.430, total=  38.9s\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=40, score=0.420, total= 1.2min\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=40, score=0.429, total= 1.1min\n",
      "[CV] classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.02, classifier__estimator__n_estimators=40, score=0.425, total= 1.2min\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=10, score=0.425, total=  23.0s\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=10, score=0.434, total=  23.1s\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=10 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=10, score=0.417, total=  22.8s\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=20, score=0.418, total=  37.7s\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=20, score=0.423, total=  38.8s\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=20 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=20, score=0.428, total=  38.6s\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=40, score=0.429, total= 1.1min\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=40, score=0.431, total= 1.2min\n",
      "[CV] classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=40 \n",
      "[CV]  classifier__estimator__learning_rate=0.05, classifier__estimator__n_estimators=40, score=0.437, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 19.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                         CountVectorizer(tokenizer=<function tokenize at 0x7f9b855b8bf8>)),\n",
       "                                                                                        ('tfidf_transformer',\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             param_grid={'classifier__estimator__learning_rate': [0.01, 0.02,\n",
       "                                                                  0.05],\n",
       "                         'classifier__estimator__n_estimators': [10, 20, 40]},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'classifier__estimator__learning_rate': [0.01, 0.02, 0.05],\n",
    "              'classifier__estimator__n_estimators': [10, 20, 40]}\n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=3, scoring='f1_weighted', verbose=3)\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c383984d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator__learning_rate': 0.01,\n",
       " 'classifier__estimator__n_estimators': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters set\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a288d",
   "metadata": {},
   "source": [
    "### 7. Test your model¶\n",
    "Show the accuracy, precision, and recall of the tuned model.\n",
    "\n",
    "Since this project focuses on code quality, process, and pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea2d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      " Accuracy: 0.8077    % Precision: 0.8313   % Recall 0.9403 \n",
      "request\n",
      " Accuracy: 0.8987    % Precision: 0.7938   % Recall 0.5501 \n",
      "offer\n",
      " Accuracy: 0.9953    % Precision: 0.4000   % Recall 0.0851 \n",
      "aid_related\n",
      " Accuracy: 0.7620    % Precision: 0.7736   % Recall 0.6022 \n",
      "medical_help\n",
      " Accuracy: 0.9323    % Precision: 0.6624   % Recall 0.2844 \n",
      "medical_products\n",
      " Accuracy: 0.9619    % Precision: 0.7233   % Recall 0.3665 \n",
      "search_and_rescue\n",
      " Accuracy: 0.9756    % Precision: 0.6995   % Recall 0.2296 \n",
      "security\n",
      " Accuracy: 0.9817    % Precision: 0.4384   % Recall 0.0853 \n",
      "military\n",
      " Accuracy: 0.9734    % Precision: 0.6809   % Recall 0.3860 \n",
      "water\n",
      " Accuracy: 0.9674    % Precision: 0.7819   % Recall 0.6784 \n",
      "food\n",
      " Accuracy: 0.9476    % Precision: 0.8199   % Recall 0.6794 \n",
      "shelter\n",
      " Accuracy: 0.9486    % Precision: 0.7975   % Recall 0.5569 \n",
      "clothing\n",
      " Accuracy: 0.9892    % Precision: 0.7583   % Recall 0.4776 \n",
      "money\n",
      " Accuracy: 0.9806    % Precision: 0.6616   % Recall 0.3537 \n",
      "missing_people\n",
      " Accuracy: 0.9900    % Precision: 0.6866   % Recall 0.1957 \n",
      "refugees\n",
      " Accuracy: 0.9701    % Precision: 0.6403   % Recall 0.2525 \n",
      "death\n",
      " Accuracy: 0.9710    % Precision: 0.7674   % Recall 0.5121 \n",
      "other_aid\n",
      " Accuracy: 0.8757    % Precision: 0.5866   % Recall 0.1808 \n",
      "infrastructure_related\n",
      " Accuracy: 0.9360    % Precision: 0.5471   % Recall 0.1103 \n",
      "transport\n",
      " Accuracy: 0.9614    % Precision: 0.7401   % Recall 0.2505 \n",
      "buildings\n",
      " Accuracy: 0.9618    % Precision: 0.6938   % Recall 0.4408 \n",
      "electricity\n",
      " Accuracy: 0.9829    % Precision: 0.6453   % Recall 0.3141 \n",
      "tools\n",
      " Accuracy: 0.9940    % Precision: 0.4615   % Recall 0.0968 \n",
      "hospitals\n",
      " Accuracy: 0.9887    % Precision: 0.4571   % Recall 0.1385 \n",
      "shops\n",
      " Accuracy: 0.9957    % Precision: 0.6667   % Recall 0.0842 \n",
      "aid_centers\n",
      " Accuracy: 0.9879    % Precision: 0.4444   % Recall 0.1469 \n",
      "other_infrastructure\n",
      " Accuracy: 0.9549    % Precision: 0.4576   % Recall 0.1166 \n",
      "weather_related\n",
      " Accuracy: 0.8771    % Precision: 0.8643   % Recall 0.6613 \n",
      "floods\n",
      " Accuracy: 0.9568    % Precision: 0.8787   % Recall 0.5505 \n",
      "storm\n",
      " Accuracy: 0.9440    % Precision: 0.7907   % Recall 0.5463 \n",
      "fire\n",
      " Accuracy: 0.9908    % Precision: 0.7045   % Recall 0.2707 \n",
      "earthquake\n",
      " Accuracy: 0.9715    % Precision: 0.8938   % Recall 0.7856 \n",
      "cold\n",
      " Accuracy: 0.9842    % Precision: 0.7387   % Recall 0.3451 \n",
      "other_weather\n",
      " Accuracy: 0.9498    % Precision: 0.5745   % Recall 0.1948 \n",
      "direct_report\n",
      " Accuracy: 0.8713    % Precision: 0.7553   % Recall 0.4967 \n",
      "label ranking average precision: 0.7219547822579523\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_train, y_prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95acc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      " Accuracy: 0.8018    % Precision: 0.8280   % Recall 0.9342 \n",
      "request\n",
      " Accuracy: 0.8972    % Precision: 0.7953   % Recall 0.5320 \n",
      "offer\n",
      " Accuracy: 0.9949    % Precision: 0.0000   % Recall 0.0000 \n",
      "aid_related\n",
      " Accuracy: 0.7549    % Precision: 0.7682   % Recall 0.5818 \n",
      "medical_help\n",
      " Accuracy: 0.9252    % Precision: 0.6138   % Recall 0.2667 \n",
      "medical_products\n",
      " Accuracy: 0.9525    % Precision: 0.6027   % Recall 0.3154 \n",
      "search_and_rescue\n",
      " Accuracy: 0.9760    % Precision: 0.6316   % Recall 0.1765 \n",
      "security\n",
      " Accuracy: 0.9796    % Precision: 0.1333   % Recall 0.0208 \n",
      "military\n",
      " Accuracy: 0.9720    % Precision: 0.5775   % Recall 0.2595 \n",
      "water\n",
      " Accuracy: 0.9599    % Precision: 0.7148   % Recall 0.6209 \n",
      "food\n",
      " Accuracy: 0.9521    % Precision: 0.8491   % Recall 0.6935 \n",
      "shelter\n",
      " Accuracy: 0.9460    % Precision: 0.7697   % Recall 0.5641 \n",
      "clothing\n",
      " Accuracy: 0.9907    % Precision: 0.7838   % Recall 0.4143 \n",
      "money\n",
      " Accuracy: 0.9798    % Precision: 0.5556   % Recall 0.2679 \n",
      "missing_people\n",
      " Accuracy: 0.9878    % Precision: 0.4737   % Recall 0.1429 \n",
      "refugees\n",
      " Accuracy: 0.9697    % Precision: 0.5714   % Recall 0.2588 \n",
      "death\n",
      " Accuracy: 0.9691    % Precision: 0.7815   % Recall 0.4777 \n",
      "other_aid\n",
      " Accuracy: 0.8640    % Precision: 0.4525   % Recall 0.1445 \n",
      "infrastructure_related\n",
      " Accuracy: 0.9352    % Precision: 0.4706   % Recall 0.0952 \n",
      "transport\n",
      " Accuracy: 0.9592    % Precision: 0.6667   % Recall 0.1787 \n",
      "buildings\n",
      " Accuracy: 0.9594    % Precision: 0.7029   % Recall 0.3606 \n",
      "electricity\n",
      " Accuracy: 0.9796    % Precision: 0.6000   % Recall 0.2087 \n",
      "tools\n",
      " Accuracy: 0.9928    % Precision: 0.2857   % Recall 0.0571 \n",
      "hospitals\n",
      " Accuracy: 0.9893    % Precision: 0.3750   % Recall 0.1154 \n",
      "shops\n",
      " Accuracy: 0.9947    % Precision: 0.2000   % Recall 0.0400 \n",
      "aid_centers\n",
      " Accuracy: 0.9855    % Precision: 0.2273   % Recall 0.0781 \n",
      "other_infrastructure\n",
      " Accuracy: 0.9535    % Precision: 0.3137   % Recall 0.0711 \n",
      "weather_related\n",
      " Accuracy: 0.8716    % Precision: 0.8609   % Recall 0.6474 \n",
      "floods\n",
      " Accuracy: 0.9575    % Precision: 0.9160   % Recall 0.5313 \n",
      "storm\n",
      " Accuracy: 0.9405    % Precision: 0.7668   % Recall 0.5010 \n",
      "fire\n",
      " Accuracy: 0.9895    % Precision: 0.4500   % Recall 0.1698 \n",
      "earthquake\n",
      " Accuracy: 0.9693    % Precision: 0.8899   % Recall 0.7845 \n",
      "cold\n",
      " Accuracy: 0.9840    % Precision: 0.7083   % Recall 0.3269 \n",
      "other_weather\n",
      " Accuracy: 0.9479    % Precision: 0.4694   % Recall 0.1723 \n",
      "direct_report\n",
      " Accuracy: 0.8592    % Precision: 0.7073   % Recall 0.4594 \n",
      "label ranking average precision: 0.7079240779396507\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, y_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658b231",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "1. try other machine learning algorithms\n",
    "2. add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3447b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                         CountVectorizer(tokenizer=<function tokenize at 0x7f9b855b8bf8>)),\n",
       "                                                                                        ('tfidf_transformer',\n",
       "                                                                                         TfidfTransformer())])),\n",
       "                                                                       ('starting_verb_transformer',\n",
       "                                                                        StartingVerbExtractor())])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__estimator__learning_rate': [0.01, 0.02,\n",
       "                                                                  0.05],\n",
       "                         'classifier__estimator__n_estimators': [10, 20, 40]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a custom transformer which will extract the starting verb of a sentence\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Starting Verb Extractor class\n",
    "    \n",
    "    This class extract the starting verb of a sentence,\n",
    "    creating a new feature for the ML classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Given it is a tranformer we can return the self \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)\n",
    "\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb_transformer', StartingVerbExtractor())\n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "\n",
    "\n",
    "cv2 = GridSearchCV(pipeline2, param_grid=parameters, scoring='f1_micro', n_jobs=-1)\n",
    "\n",
    "cv2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e9c1a",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(cv):\n",
    "    \"\"\"\n",
    "    Function: save model as pickle file.\n",
    "    Args:\n",
    "      cv:target model\n",
    "    Return:\n",
    "      N/A\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('classifier.pkl', 'wb') as file:\n",
    "        pickle.dump(cv, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26959b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model\n"
     ]
    }
   ],
   "source": [
    "print(\"Save model\")\n",
    "save_model(cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d56889",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete train.py\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
